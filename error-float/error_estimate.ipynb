{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error in Floating Point System\n",
    "\n",
    "Let's start from a simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a64 + b64 = 0.21000000000000002\n",
      "a32 + b32 = 0.21000001f0\n"
     ]
    }
   ],
   "source": [
    "a64 = 0.01\n",
    "b64 = 0.2\n",
    "@show a64 + b64;\n",
    "a32 = Float32(0.01)\n",
    "b32 = Float32(0.2)\n",
    "@show a32 + b32;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IEEE 754: Standard of Floating Point Number\n",
    "\n",
    "The IEEE 754 standard is a binary floating-point arithmetic standard used to represent and process real numbers in computers and other digital devices. The standard defines two floating-point formats: single-precision and double-precision, which use 32 bits and 64 bits respectively to represent a floating-point number. These formats use scientific notation to represent real numbers, with three parts: sign, exponent, and mantissa.\n",
    "\n",
    "The IEEE 754 standard also defines arithmetic operations such as addition, subtraction, multiplication, and division, as well as rounding rules for performing arithmetic operations on these floating-point numbers. These rules ensure the precision and reproducibility of floating-point arithmetic operations performed in computers.\n",
    "\n",
    "A floating point number can be give as\n",
    "$$\n",
    "a = ±m \\cdot \\beta^e, m = (0.d_1 d_2 ... d_t)_\\beta, 0 ≤ d_i< \\beta\\;,\n",
    "$$\n",
    "so that the rounding error will be $\\frac{1}{2} \\beta^{1-t}$ and the chopping error will be $\\beta^{1-t}$.\n",
    "\n",
    "By IEEE 754, in single precision a ﬂoating-point number $a$ is stored as the sign $s$ (one bit), the exponent $e$ (8 bits), and the mantissa $m$ (23 bits).\n",
    "In double precision 11 of the 64 bits are used for the exponent, and 52 bits are used for the mantissa.\n",
    "So that the rounding error of Float32 and Float64 are about $5.94 \\cdot 10^{-8}$ and $1.11 \\cdot 10^{-16}$.\n",
    "\n",
    "The IEEE standard also includes two extended precision formats that offer extra precision and exponent range. The standard only speciﬁes a lower bound on how many extra bits it provides. 33 Most modern processors use 80-bit registers for processing real numbers and store results as 64-bit numbers according to the IEEE double precision standard. Extended formats simplify tasks such as computing elementary functions accurately in single or double precision. Extended precision formats are used also by hand calculators. These will often display 10 decimal digits but use 13 digits internally—“the calculator knows more than it shows.”\n",
    "\n",
    "\n",
    "### Guard digits\n",
    "\n",
    "The guard digit is an extra digit used in floating-point arithmetic to improve the accuracy of computations. It is a bit that is added to the least significant bit of the mantissa of a floating-point number, and it represents an additional bit of precision that is used during arithmetic operations.\n",
    "\n",
    "The guard digit is used to prevent rounding errors that may occur during arithmetic operations, especially when intermediate results are very close to the boundary between two representable floating-point numbers. By adding an extra bit of precision, the guard digit helps to ensure that the final result is as accurate as possible.\n",
    "\n",
    "For example, consider the addition of two floating-point numbers that have a very small difference between their values. Without a guard digit, the result of the addition may need to be rounded, which could introduce a small error. With a guard digit, the addition can be performed with greater precision, reducing the likelihood of rounding errors and improving the accuracy of the final result.\n",
    "\n",
    "![image.png](./flIEEE.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Propragration\n",
    "\n",
    "### Operations in Floating Point Number System\n",
    "\n",
    "Define the basic floating-point operations are given as\n",
    "$$\n",
    "fl(x + y),~fl(x-y),~fl(x\\times y)~\\text{and}~fl(x / y)\n",
    "$$\n",
    "and the standard model holds because of the existence of the guard digits:\n",
    "$$\n",
    "fl(x ~\\text{op} ~y) = (x ~\\text{op} ~y) (1 + \\delta),~|\\delta| \\leq u \\;.\n",
    "$$\n",
    "In computers support a *fused multiply-add* operation and have only one rounding error\n",
    "$$\n",
    "fl(a\\times x + y) = (a \\times x + y) (1 + \\delta),~|\\delta| \\leq u \\;,\n",
    "$$\n",
    "so it is not only about speed but also accuracy.\n",
    "\n",
    "The rule for the complex number is a litte bit different, given by\n",
    "\n",
    "![image.png](./complex_rule.png)\n",
    "\n",
    "where $\\gamma_n = \\frac{nu}{1 - nu}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can have a check on another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error natural = 0.00010874912467651043\n",
      "error opposite = 3.0252606197933574e-8\n"
     ]
    }
   ],
   "source": [
    "sum_natural = sum(Float32(Float32(1)/Float32(i)^Float32(2)) for i= 1:10000)\n",
    "sum_opposite = sum(Float32(Float32(1)/Float32(10001 - i)^Float32(2)) for i= 1:10000)\n",
    "sum_exact = sum(1.0/(i^2) for i in 1:10000)\n",
    "println(\"error natural = \", abs(sum_exact - sum_natural))\n",
    "println(\"error opposite = \", abs(sum_exact - sum_opposite))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This clearly shows the error of the $fl(x~\\text{op}~y)$ depends on value of $x~\\text{op}~y$, changing the summation order may change a lot.\n",
    "\n",
    "The compensated summation method can be used in such cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compensated_summation (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function compensated_summation(x::Vector{T}) where T\n",
    "    s = x[1]\n",
    "    c = zero(T)\n",
    "    for i in 2:length(x)\n",
    "        y = c + x[i]\n",
    "        t = s + y\n",
    "        c = (s - t) + y\n",
    "        s = t\n",
    "    end\n",
    "    return s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error special = 3.0252606197933574e-8\n"
     ]
    }
   ],
   "source": [
    "error_special = abs(compensated_summation([Float32(1 / i^2) for i in 1:10000]) - sum_exact)\n",
    "println(\"error special = \", error_special)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Propragation\n",
    "\n",
    "The very basic rule of error propragation can be given as \n",
    "$$\n",
    "|\\Delta f| \\leq \\sum_i |\\frac{\\partial f}{\\partial x_i} \\Delta x_i|\\;.\n",
    "$$\n",
    "\n",
    "We can also define conditional number as\n",
    "$$\n",
    "\\kappa(f;x) = \\frac{||J(x)||~||x||}{||f(x)||}\\;.\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](./conditional_number.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
